\section{Gradient Descent}

\sectionauthor{ Leo Bergmann, Benjamin Knöbel del Olmo, Cedric Balzer}



Wie in der Betrachtung von eindimensionalen Funktionen, werden für die Bestimmung der Extrema auch bei mehrdimensionalen Funktionen Ableitungen eingesetzt. Diese werden nicht mehr durch reelle Zahlen, sondern durch Vektoren ausgedrückt. Gegeben sei eine differenzierbare und konvexe Funktion $ f:\mathbb{R}^n \rightarrow \mathbb{R}, x \mapsto f(x). $ Die Ableitung von f an einem Punkt entspricht einem N-Dimensionalen Vektor. Diese Vektor wird Gradient genannt und seine Spitze zeigt immer in Richtung des stärksten Anstiegs, wobei dessen Länge der Steigung entspricht.

Der darauf basierende Gradient Descent Algorithmus wird verwendet, um das Minimum einer Fuktion zu approximieren. Dies wird durch einen iterativen Ansatz erreicht: An einem zufällig gewählten Startpunkt wird zunächst der Gradient ermittelt. Danach wird als neuen Startpunkt derjenige definiert, der durch das Gehen in die entgegengesetzte Richtung des Gradienten erreicht wird. Die Länge des gegangenen Schrittes hängt von der Länge des Gradienten ab, die durch eine Konstante, die Learning Rate, skaliert wird. Dies ermöglicht eine freie Adjustierung der Schrittgrößen, um das Minimum genauer zu treffen. Der Algorithmus endet, wenn die davor definierte, maximale Anzahl an Durchläufen erreicht, oder wenn die Schrittlänge kleiner als eine davor definierte Toleranz ist. Der Gradient Descent ist also ein Näherungs-/Optimierungsalgorithmus.



Vorausgesetzt wird, dass die Funktion differenzierbar und konvex ist, das heißt das die Verbindungslinie zwischen zwei Punkten des Graphens immer über dem Graphen liegt. Auch Funktionen mit Sattelpunkt oder die Wahl einer unpassenden Learning Rate bei der Implementierung können zu falschen Ergebnissen und langen Laufzeiten führen. Das liegt daran, dass bei zu großen Learning Rates das Minimum einfach übergangen wird, während bei zu kleinen Learning Rates der Algorithmus in lokalen Minima „stecken“ bleibt, wobei das Programm dann ohne wesentliche numerische Verbesserung weiterläuft.
